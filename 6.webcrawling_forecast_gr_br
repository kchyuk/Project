import collections
import warnings;

warnings.filterwarnings('ignore')

from selenium import webdriver
from selenium.webdriver.common.keys import Keys

chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')

from konlpy.tag import Kkma;

kkma = Kkma()
from konlpy.tag import Okt;

okt = Okt()

import pandas as pd

import time

import matplotlib
import matplotlib.pyplot as plt
from IPython.display import set_matplotlib_formats

matplotlib.rcParams['font.family'] = 'Malgun Gothic'
matplotlib.rcParams['axes.unicode_minus'] = False
matplotlib.rc('font', family='Malgun Gothic')
set_matplotlib_formats('retina')
matplotlib.rc('axes', unicode_minus=False)

from wordcloud import WordCloud
from IPython.display import set_matplotlib_formats

wd = webdriver.Chrome('chromedriver', options=chrome_options)

from urllib.request import *
from bs4 import *
from urllib.parse import quote

# 부도(bankruptcy) 키워드
wd.get("https://finance.naver.com/news/news_search.naver");
time.sleep(0.5)
search_box = wd.find_element_by_name("q");
search_box.send_keys('부도');
search_box.send_keys(Keys.RETURN)

news_list_br = []
for a in range(20):
    wd.get(
        "https://finance.naver.com/news/news_search.naver?rcdate=&q=%BA%CE%B5%B5&x=26&y=14&sm=all.basic&pd=1&stDateStart=2019-04-09&stDateEnd=2022-04-09&page=" + str(
            a + 1));
    time.sleep(0.4)

    for dt in wd.find_elements_by_css_selector('#contentarea_left > div.newsSchResult > dl > dt> a'):
        news_list_br.append(dt.text)

    for dd in wd.find_elements_by_css_selector('#contentarea_left > div.newsSchResult > dl > dd > a'):
        news_list_br.append(dd.text)

while '' in news_list_br:
    news_list_br.remove('')

word_list_br = sum([okt.nouns(d) for d in news_list_br], [])  # 단어만 추출

# 성장(growth) 키워드
wd.get("https://finance.naver.com/news/news_search.naver");
time.sleep(0.5)
search_box = wd.find_element_by_name("q");
search_box.send_keys('성장');
search_box.send_keys(Keys.RETURN)

news_list_growth = []
for a in range(20):
    wd.get(
        "https://finance.naver.com/news/news_search.naver?rcdate=&q=%BC%BA%C0%E5&x=0&y=0&sm=all.basic&pd=4&stDateStart=2017-04-10&stDateEnd=2022-04-10&page=" + str(
            a + 1));
    time.sleep(0.4)

    for dt in wd.find_elements_by_css_selector('#contentarea_left > div.newsSchResult > dl > dt> a'):
        news_list_growth.append(dt.text)

    for dd in wd.find_elements_by_css_selector('#contentarea_left > div.newsSchResult > dl > dd > a'):
        news_list_growth.append(dd.text)

while '' in news_list_growth:
    news_list_growth.remove('')

word_list_growth = sum([okt.nouns(d) for d in news_list_growth], [])  # 단어만 추출

# 부도데이터셋 과 성장데이터셋을 만들기 위해 교집합 제거


word_list_br;
word_list_br2 = word_list_br.copy()  # 부도 키워드 리스트를 카피
word_list_growth;
word_list_growth2 = word_list_growth.copy()  # 성장 키워드 리스트를 카피
부도_remove_list = ['최신원', '대식', '반디앤루니스', '성실', '마리나', '열흘', '우리은행', '이재명', '스리랑카', '지난달', '의장', '새해', '대선', '용평', '네트웍']
성장_remove_list = ['추경호', '이창', '후보자', '푸르덴셜생명', '엑소', '프레', '지오', '윤종원', '련']

for a in word_list_growth:
    if a in word_list_br2:
        while a in word_list_br2:
            word_list_br2.remove(a)  # word_list_br2 에는 고유한 부도 키워드만 남음 (부도&성장 키워드 중 겹치는 키워드 제거)
counts_br = collections.Counter(word_list_br2)  # word_list_br2를 dict 형태로 만듦

for b in word_list_br:
    if b in word_list_growth2:
        while b in word_list_growth2:
            word_list_growth2.remove(b)  # word_list_growth2 에는 고유한 성장 키워드만 남음 (부도&성장 키워드 중 겹치는 키워드 제거)
counts_growth = collections.Counter(word_list_growth2)  # word_list_growth2를 dict 형태로 만듦

# 부도데이터셋 만들기
dataset_br_dict = {}
for a, b in zip(counts_br.keys(), counts_br.values()):
    if b >= 10:
        if a not in 부도_remove_list:
            dataset_br_dict[a] = b  # dataset_br_dict 에는 빈도수 10개 이상 및 특정 키워드 제거된 값이 남아있음

dataset_br_list = []
for a, b in zip(dataset_br_dict.keys(), dataset_br_dict.values()):
    for c in range(b):
        dataset_br_list.append(a)  # dataset_br_dict를 리스트 형태로 만들어 dataset_br_list 에 저장

dataset_br_df = pd.DataFrame(list(dataset_br_dict.items()), columns=['단어', '빈도수'])  # 데이터프레임
dataset_br_df.sort_values('빈도수', ascending=False, inplace=True)  # 빈도수 기준으로 정렬

plt.figure(figsize=(15, 6))  # 그래프 크기 지정
plt.xticks(fontsize=10, rotation=45)
plt.bar(dataset_br_df.head(20)['단어'], dataset_br_df.head(20)['빈도수'])
plt.show();

wordcloud = WordCloud(font_path='C:/Windows/Fonts/malgun.ttf', background_color='white', colormap="Accent_r",
                      width=1500, height=1000).generate_from_frequencies(dataset_br_dict)
plt.imshow(wordcloud)
plt.axis('off')
plt.show()

# 성장데이터셋 만들기
dataset_growth_dict = {}
for a, b in zip(counts_growth.keys(), counts_growth.values()):
    if b >= 10:
        if a not in 성장_remove_list:
            dataset_growth_dict[a] = b  # dataset_growth_dict 에는 빈도수 10개 이상 및 특정 키워드 제거된 값이 남아있음

dataset_growth_list = []
for a, b in zip(dataset_growth_dict.keys(), dataset_growth_dict.values()):
    for c in range(b):
        dataset_growth_list.append(a)  # dataset_growth_dict를 리스트 형태로 만들어 dataset_growth_list 에 저장

dataset_growth_df = pd.DataFrame(list(dataset_growth_dict.items()), columns=['단어', '빈도수'])  # 데이터프레임
dataset_growth_df.sort_values('빈도수', ascending=False, inplace=True)  # 빈도수 기준으로 정렬

plt.figure(figsize=(15, 6))  # 그래프 크기 지정
plt.xticks(fontsize=10, rotation=45)
plt.bar(dataset_growth_df.head(20)['단어'], dataset_growth_df.head(20)['빈도수'])
plt.show();

wordcloud = WordCloud(font_path='C:/Windows/Fonts/malgun.ttf', background_color='white', colormap="Accent_r",
                      width=1500, height=1000).generate_from_frequencies(dataset_growth_dict)
plt.imshow(wordcloud)
plt.axis('off')
plt.show()


# 특정 기업의 부도경향성 및 성장경향성을 예측
def forcast_br_growth():
    global query
    query = quote(input('원하는 기업명을 입력하세요: '))
    global page
    page = int(input('몇 페이지까지 가져올까요? '))

    global news_list_기업
    news_list_기업 = []

    for a in range(page):
        url = "https://search.naver.com/search.naver?where=news&sm=tab_pge&query=" + query + "&sort=0&photo=0&field=0&pd=0&ds=&de=&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start=" + str(
            a + 1) + "1"
        req = Request(url)
        req.add_header('User-Agent', 'Mozilla/5.0')  # 정상적인 웹 크롤러라고 헤더에 표시
        wp = urlopen(req);
        soup = BeautifulSoup(wp, 'html.parser')  # parsing
        divlist = soup.find_all('a', {'class': 'news_tit'})  # a태그 중에 class 가 news_tit 인 것을 찾기

        [news_list_기업.append(divlist[b].get_text()) for b in range(10)]

    global word_list_기업
    word_list_기업 = sum([okt.nouns(d) for d in news_list_기업], [])  # 단어만 추출

    global 부도;
    global 성장
    부도 = 0;
    성장 = 0

    for x in word_list_기업:  # word_list_기업의 단어가 dataset_br_list에 있으면 부도 1씩 증가
        if x in dataset_br_list:
            부도 += 1

    for y in word_list_기업:  # word_list_기업의 단어가 dataset_growth_list 있으면 성장 1씩 증가
        if y in dataset_growth_list:
            성장 += 1

    부도경향성 = round((부도 / len(word_list_기업)) * 100, 2)
    성장경향성 = round((성장 / len(word_list_기업)) * 100, 2)

    print("\n", f'부도경향성은 {부도경향성}% 이고 성장경향성은 {성장경향성}% 입니다.')

    ratio = [부도, 성장];
    labels = ['부도', '성장', ];
    explode = [0.07, 0.07];
    colors = ['silver', 'gold']
    plt.pie(ratio, labels=labels, autopct='%.1f%%', startangle=260, counterclock=False, explode=explode
            , shadow=True, colors=colors)
    plt.title('부도경향성 단어와 성장경향성 단어의 비율')
    plt.show()


forcast_br_growth()
